{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Schindler/Documents/Schindler_Lab/ML projects/TILES/Data/EMA PsyFlex.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path)\n",
    "data = pd.DataFrame(data = data)\n",
    "print('Original PsyFlex EMA shape:\\n', data.shape, '\\n')\n",
    "#replace empty values with 0 (e.g. these are not missing values but incorrectly entered)\n",
    "data.replace(to_replace=' ', value= 0, inplace=True)\n",
    "print('Original PsyFlex EMA survey type counts:\\n', data['survey_type'].value_counts(), '\\n')\n",
    "print('Original PsyFlex EMA missing value couts:\\n', data.isnull().sum(), '\\n')\n",
    "#determine data types\n",
    "print('Original PsyFlex EMA data types:\\n', data.info(), '\\n')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select survey type\n",
    "data_psych_flex_orig = data[data['survey_type'] == 'psych_flex']\n",
    "print('Original PsyFlex survey shape:\\n', data_psych_flex_orig.shape, '\\n')\n",
    "\n",
    "#drop individual questions\n",
    "data_psych_flex_orig_short = data_psych_flex_orig[['Timestamp', 'survey_id', 'participant_id', 'ID', 'survey_type',\n",
    "       'survey_dt', 'completed_ts_utc', 'PsyFlex',\n",
    "       'Psy_Flex_SD', 'Conttext_All', 'Context_Neg', 'Context_Pos']]\n",
    "\n",
    "#set index\n",
    "data_psych_flex_orig_short.set_index(['Timestamp', 'survey_id', 'participant_id', 'ID', 'survey_type', 'survey_dt', 'completed_ts_utc'], inplace=True)\n",
    "\n",
    "#find how many missing\n",
    "print('Original PsyFlex survey data missing value counts:\\n', data_psych_flex_orig_short.isnull().sum(), '\\n')\n",
    "\n",
    "#drop anything with a na\n",
    "data_psych_flex_nonull = data_psych_flex_orig_short.dropna()\n",
    "#confirm no more missing\n",
    "print('Missing check:\\n', data_psych_flex_nonull.isnull().sum(), '\\n')\n",
    "\n",
    "print('No null PsyFlex survey shape:\\n', data_psych_flex_nonull.shape, '\\n')\n",
    "\n",
    "print(\"Fraction of data kept:\\n\",float(data_psych_flex_nonull.shape[0])/data_psych_flex_orig_short.shape[0], '\\n')\n",
    "\n",
    "#convert data types\n",
    "data_psych_flex_nonull['PsyFlex'] = data_psych_flex_nonull['PsyFlex'].astype('float')\n",
    "data_psych_flex_nonull['Psy_Flex_SD'] = data_psych_flex_nonull['Psy_Flex_SD'].astype('float')\n",
    "data_psych_flex_nonull['Conttext_All'] = data_psych_flex_nonull['Conttext_All'].astype('float')\n",
    "data_psych_flex_nonull['Context_Neg'] = data_psych_flex_nonull['Context_Neg'].astype('float')\n",
    "data_psych_flex_nonull['Context_Pos'] = data_psych_flex_nonull['Context_Pos'].astype('float')\n",
    "\n",
    "print(\"Confirm data type float:\\n\", data_psych_flex_nonull.info(), '\\n')\n",
    "\n",
    "data_psych_flex_nonull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_psych_flex_nonull, kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_psych_flex_nonull.corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_flex_regressor = data_psych_flex_nonull['PsyFlex']\n",
    "psy_flex_features = data_psych_flex_nonull[['Context_Pos']]\n",
    "psy_flex_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(psy_flex_features, psy_flex_regressor, test_size = .3, random_state=1)\n",
    "\n",
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=3)\n",
    "cv = list(k_fold.split(features_scaled, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_cv = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "lr_cv = LinearRegression()\n",
    "rf_cv = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "svm_cv = SVC(probability=True) \n",
    "kn_cv = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dm = cross_val_predict(dm_cv, features_scaled, y_train, cv=cv, method='predict')\n",
    "#y_pred_prob_dm = cross_val_predict(dm_cv, features_scaled, y_train, cv=cv, method='predict_proba')\n",
    "#conf_mat_dm = confusion_matrix(y_train, y_pred_dm)\n",
    "#conf_mat_dm\n",
    "dm_cv.fit(features_scaled, y_train)\n",
    "y_pred_dummy = dm_cv.predict(features_scaled)\n",
    "print(\"r^2 for dummy data:\", metrics.r2_score(y_train, y_pred_dummy))\n",
    "print(\"MAE for dummy data:\",metrics.mean_absolute_error(y_train, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = cross_val_predict(lr_cv, features_scaled, y_train, cv=cv, method='predict')\n",
    "#y_pred_prob_lr = cross_val_predict(lr_cv, features_scaled, y_train, cv=cv, method='predict_proba')\n",
    "#conf_mat_lr = confusion_matrix(y_train, y_pred_lr)\n",
    "#conf_mat_lr\n",
    "lr_cv.fit(features_scaled, y_train)\n",
    "y_pred_lr = lr_cv.predict(features_scaled)\n",
    "print(\"r^2 for lr data:\", metrics.r2_score(y_train, y_pred_lr))\n",
    "print(\"MAE for lr data:\",metrics.mean_absolute_error(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = cross_val_predict(rf_cv, features_scaled, y_train, cv=cv, method='predict')\n",
    "#y_pred_prob_rf = cross_val_predict(rf_cv, features_scaled, y_train, cv=cv, method='predict_proba')\n",
    "#conf_mat_rf = confusion_matrix(y_train, y_pred_rf)\n",
    "#conf_mat_rf\n",
    "rf_cv.fit(features_scaled, y_train)\n",
    "y_pred_lr = rf_cv.predict(features_scaled)\n",
    "print(\"r^2 for rf data:\", metrics.r2_score(y_train, y_pred_lr))\n",
    "print(\"MAE for rf data:\",metrics.mean_absolute_error(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=1)\n",
    "    km_ss.fit(features_clust_scaled)\n",
    "    scores.append(silhouette_score(features_clust_scaled, km_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km2 = KMeans(n_clusters=2,random_state=1234)\n",
    "km2.fit(features_clust_scaled)\n",
    "data['kmeans_2_scaled'] = [ \"cluster_\" + str(label) for label in km2.labels_ ]\n",
    "data.groupby('kmeans_2_scaled').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
