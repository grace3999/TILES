{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careless responder feature engineering and analysis (focus on engage_psycap survey only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from itertools import groupby\n",
    "import datetime as dt\n",
    "from numpy import median\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/TILES/final_data/data_final_combined.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv containing participant info\n",
    "data = pd.read_pickle(data_path)\n",
    "data = pd.DataFrame(data = data)\n",
    "#data_PF.reset_index(inplace=True)\n",
    "\n",
    "print('Original data shape:\\n', data.shape, '\\n')\n",
    "#ensure no replicate ID (212 participants in study)\n",
    "print('Original data unique IDs:\\n', data['ParticipantID'].unique().shape, '\\n')\n",
    "#ensure no replicate ID (212 participants in study)\n",
    "print('Original data unique IDs:\\n', data['MitreID'].unique().shape, '\\n')\n",
    "#how much missing data is there?\n",
    "print('Original data missing value counts:\\n', data.isnull().sum(), '\\n')\n",
    "#what is the data type of each column?\n",
    "print('Original data data types:\\n', data.info(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be 71\n",
    "len(data['wave_study_day'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes for CR features for Engage\n",
    "\n",
    "Should have answered every question\n",
    "\n",
    "Longstring\n",
    "- All questions use same scale (1=not at all, 7=very much), but there are 5 different constructs assessed\n",
    "    - make column with longest string\n",
    "    - make column with number that longest string consisted of\n",
    "\n",
    "Semantic consistency\n",
    "- Internal consistency (within construct) should be greater than consistency across constructs\n",
    "\n",
    "Semantic antonyms\n",
    "- Not applicable\n",
    "\n",
    "Semantic synonyms \n",
    "- Hindrance stressors should be negatively correlated with support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off completed PF and related columns\n",
    "engage_psycap_only = data[(data['survey_type'] == 'engage_psycap') & (data['completed'] == 1.0)]\n",
    "\n",
    "\n",
    "engage_psycap_only.shape\n",
    "engage_psycap_only['ParticipantID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_psycap_only = engage_psycap_only[['index', 'MitreID', 'ParticipantID', 'PrimaryUnit', 'SmartPhone',\n",
    "       'Sex', 'Shift', 'Wave', 'survey_id', 'survey_type', 'date_time',\n",
    "       'date', 'time', 'Timesent', 'completed', 'start_delay',\n",
    "       'time_to_complete', 'activity_num', 'location_num',\n",
    "       'engage_location', 'engage_activity', 'engage_3', 'engage_4',\n",
    "       'engage_5', 'engage_6', 'engage_7', 'engage_8', 'engage_9',\n",
    "       'engage_10', 'engage_11', 'engage_12', 'engage_13', 'engage_14',\n",
    "       'engage_15', 'engage_16', 'engage_17', 'engage_18', 'engage_19',\n",
    "       'engage_20', 'engage_21', 'engage_22', 'engage_23', 'engage_24',\n",
    "       'engage_25', 'engage_26', 'engage_27', 'engage_28', 'engage_29',\n",
    "       'engage_mgt', 'psycap_mgt', 'support_mgt', 'challenge_mgt',\n",
    "       'hindrance_mgt',\n",
    "       'wave_study_date', 'wave_study_day',\n",
    "       'survey_count', 'day_of_week', 'working', 'at_work']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create study date bins\n",
    "engage_psycap_only['wave_study_date_bin'] = pd.cut(engage_psycap_only['wave_study_day'], 5)\n",
    "engage_psycap_only['wave_study_date_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is count of missing values from survey\n",
    "engage_psycap_only.loc[engage_psycap_only.loc[:, 'engage_location':'engage_29'].isnull().sum(axis=1) > 0, 'missing_values'] = engage_psycap_only.loc[:, 'engage_location':'engage_29'].isnull().sum(axis=1)\n",
    "engage_psycap_only.loc[engage_psycap_only.loc[:, 'engage_location':'engage_29'].isnull().sum(axis=1) == 0, 'missing_values'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is number of surveys that were not completed\n",
    "\n",
    "part_id = engage_psycap_only['ParticipantID'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    missing = 19 - engage_psycap_only[engage_psycap_only['ParticipantID'] == participant]['survey_count'].max()\n",
    "    engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant), 'uncompleted'] = missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is number of surveys that were not completed within wave study date bin\n",
    "\n",
    "part_id = engage_psycap_only['ParticipantID'].unique()\n",
    "day_bins = engage_psycap_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    for unique_bin in day_bins:\n",
    "        missing = 6 - engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin)].shape[0]\n",
    "        if missing < 0:\n",
    "            missing = 0\n",
    "        engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin), 'uncompleted_day_bin'] = missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long string analysis (e.g. max length of same number answered for 'engage_location':'engage_29')\n",
    "#create features related to long string analysis (feature of how long the string is and feature of what the string consisted of)\n",
    "\n",
    "max_strings = []\n",
    "max_answers = []\n",
    "\n",
    "for index, row in engage_psycap_only.iterrows():\n",
    "    \n",
    "    groups = groupby(row['engage_location':'engage_29'])\n",
    "    result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "\n",
    "    max_pair = max(result, key=lambda x:x[1])\n",
    "    max_string_length = max_pair[1]\n",
    "    max_answer = max_pair[0]\n",
    "\n",
    "    max_strings.append(max_string_length)\n",
    "    \n",
    "    max_answers.append(max_answer)\n",
    "\n",
    "engage_psycap_only['longest_string_count'] = max_strings\n",
    "engage_psycap_only['longest_string_answer'] = max_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of average longstring during first day bin to average longstring during last time bin\n",
    "\n",
    "part_id = engage_psycap_only['ParticipantID'].unique()\n",
    "day_bins = engage_psycap_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    string_1 = engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == day_bins[0])]['longest_string_count'].mean() \n",
    "    string_2 = engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == day_bins[-1])]['longest_string_count'].mean()\n",
    "\n",
    "    engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant), 'longest_string_ratio'] = string_2 / string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of average longstring during current bin to average longstring during last time bin\n",
    "\n",
    "part_id = engage_psycap_only['ParticipantID'].unique()\n",
    "day_bins = engage_psycap_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    for unique_bin in day_bins:\n",
    "        string_1 = engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin)]['longest_string_count'].mean() \n",
    "        string_2 = engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == day_bins[-1])]['longest_string_count'].mean()\n",
    "\n",
    "        engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin), 'longest_string_ratio_bin'] = string_2 / string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of number of longstrings over 7 to total number of surveys taken\n",
    "\n",
    "part_id = engage_psycap_only['ParticipantID'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    count_over_7 = engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['longest_string_count'] >= 13)].shape[0]\n",
    "    \n",
    "    engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant), 'ls_ratio'] = count_over_7 / engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of number of longstrings over 7 during current bin to total number of surveys taken for that bin\n",
    "\n",
    "part_id = engage_psycap_only['ParticipantID'].unique()\n",
    "day_bins = engage_psycap_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    for unique_bin in day_bins:\n",
    "        count_over_7 = engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) \n",
    "                                           & (engage_psycap_only['longest_string_count'] >= 13) \n",
    "                                           & (engage_psycap_only['wave_study_date_bin'] == unique_bin)].shape[0]\n",
    "        try:\n",
    "            engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin), 'ls_ratio_bin'] = count_over_7 / engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin)].shape[0]\n",
    "        except:\n",
    "            engage_psycap_only.loc[(engage_psycap_only['ParticipantID'] == participant) & (engage_psycap_only['wave_study_date_bin'] == unique_bin), 'ls_ratio_bin'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is binary for if time_to_complete is very short or long (0 is neither)\n",
    "bad_times_low = []\n",
    "bad_times_high = []\n",
    "\n",
    "for index, row in engage_psycap_only.iterrows():\n",
    "    \n",
    "    if (row['time_to_complete'] <= 20): \n",
    "        bad_times_low.append(1)\n",
    "    else:\n",
    "        bad_times_low.append(0)\n",
    "    \n",
    "    if (row['time_to_complete'] > 1200): \n",
    "        bad_times_high.append(1)\n",
    "    else:\n",
    "        bad_times_high.append(0)\n",
    "\n",
    "engage_psycap_only['bad_times_low'] = bad_times_low\n",
    "engage_psycap_only['bad_times_high'] = bad_times_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_psycap_CR = engage_psycap_only[['MitreID', 'ParticipantID', 'PrimaryUnit', 'SmartPhone',\n",
    "       'Sex', 'Shift', 'Wave', 'survey_type', 'start_delay',\n",
    "       'time_to_complete', 'activity_num', 'location_num',\n",
    "       'engage_location', 'engage_activity', 'engage_mgt', 'psycap_mgt', 'support_mgt', 'challenge_mgt',\n",
    "       'hindrance_mgt',\n",
    "       'wave_study_day', 'survey_count', 'day_of_week', 'working',\n",
    "       'wave_study_date_bin', 'missing_values', 'uncompleted',\n",
    "       'uncompleted_day_bin', 'longest_string_count',\n",
    "       'longest_string_answer', 'longest_string_ratio',\n",
    "       'longest_string_ratio_bin', 'bad_times_low', 'bad_times_high', 'ls_ratio', 'ls_ratio_bin']]\n",
    "\n",
    "engage_psycap_CR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_demog_prepost = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/TILES/final_data/Demog, PRE, PST survey composites.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data_demog_prepost, contains demographic information and pre/post questionaires\n",
    "data_demog_prepost = pd.read_csv(path_demog_prepost)\n",
    "data_demog_prepost = pd.DataFrame(data = data_demog_prepost)\n",
    "print('Original demog_prepost shape:\\n', data_demog_prepost.shape, '\\n')\n",
    "#replace blnaks with nans\n",
    "data_demog_prepost = data_demog_prepost.replace(' ', np.nan)\n",
    "#ensure no replicate ID (eg one row per participant in study)\n",
    "print('Original demog_prepost unique IDs:\\n', data_demog_prepost['ID'].unique().shape, '\\n')\n",
    "print('Original demog_prepost missing value couts:\\n', data_demog_prepost.isnull().sum(), '\\n')\n",
    "print('Original demog_prepost data types:\\n', data_demog_prepost.info(), '\\n')\n",
    "data_demog_prepost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the information contained in data_demog_prepost to psych_flex_CR\n",
    "#first create new data table of data_demog_prepost that contains the same number of rows for each participant in that is in psych_flex_CR\n",
    "#(e.g. replicate data_demog_prepost so same length as psych_flex_CR for each participant)\n",
    "\n",
    "participants = engage_psycap_CR['MitreID'].unique()\n",
    "\n",
    "engage_CR_demog = pd.DataFrame()\n",
    "\n",
    "for part in participants:\n",
    "    df_part_long = pd.concat([data_demog_prepost[data_demog_prepost['ID'] == part]]*len(engage_psycap_CR[engage_psycap_CR['MitreID'] ==  part]), ignore_index=True)\n",
    "    df_part_long.reset_index(inplace=True)\n",
    "    engage_CR_demog_int = pd.concat([df_part_long, engage_psycap_CR[engage_psycap_CR['MitreID'] ==  part].reset_index()], axis = 1)\n",
    "    engage_CR_demog = engage_CR_demog.append(engage_CR_demog_int)\n",
    "\n",
    "#confirm the two data tables are now the same lenght\n",
    "print('psych_flex_CR and psych_flex_CR_demog are the same length:', engage_psycap_CR.shape[0] == engage_CR_demog.shape[0])\n",
    "print(engage_psycap_CR.shape[0])\n",
    "print(engage_CR_demog.shape[0])\n",
    "print('does the math make sense?', engage_CR_demog.shape[0] == (engage_CR_demog['ID'].values == engage_CR_demog['MitreID'].values).sum())\n",
    "engage_CR_demog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_CR_demog_features = ['MitreID', 'ParticipantID',\n",
    "       'PrimaryUnit', 'SmartPhone', 'Sex', 'Shift', 'Wave', 'bornUS', 'lang', 'englyrs', \n",
    "                       'activity_num', 'location_num',\n",
    "       'engage_location', 'engage_activity', 'engage_mgt', 'psycap_mgt', 'support_mgt', 'challenge_mgt',\n",
    "       'hindrance_mgt', 'ocb', 'inter.deviance', 'org.deviance', 'extraversion',\n",
    "       'agreeableness', 'conscientiousness', 'neuroticism', 'openness',\n",
    "       'psqi', 'fatigue', 'Stress', \n",
    "       'Flexibility', 'Inflexibility', 'Engagement', 'start_delay',\n",
    "       'time_to_complete', 'wave_study_day', 'survey_count', 'day_of_week',\n",
    "       'working', 'wave_study_date_bin', 'missing_values', 'uncompleted',\n",
    "       'uncompleted_day_bin', 'longest_string_count',\n",
    "       'longest_string_answer', 'longest_string_ratio',\n",
    "       'longest_string_ratio_bin', 'bad_times_low', 'bad_times_high',\n",
    "       'ls_ratio', 'ls_ratio_bin']\n",
    "\n",
    "\n",
    "engage_CR_demog_df = engage_CR_demog[engage_CR_demog_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "engage_CR_demog_df.to_csv('engage_CR_demog_df.csv')\n",
    "\n",
    "#pickle to save\n",
    "engage_CR_demog_df.to_pickle('engage_CR_demog_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_CR_demog_df.groupby('wave_study_date_bin').corr().to_csv('corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"longest_string_count\", data=engage_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engage_CR_demog_df['longest_string_answer'] = engage_CR_demog_df['longest_string_answer'].astype(float)\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"longest_string_answer\", data=engage_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"longest_string_ratio_bin\", data=engage_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"ls_7_ratio_bin\", data=engage_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"longest_string_count\", y=\"bad_times_high\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', col_wrap=3)\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"longest_string_count\", y=\"ls_7_ratio\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', col_wrap=3)\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = engage_CR_demog_df['MitreID'].unique()\n",
    "for u_id in unique_ids:\n",
    "    g = sns.catplot(x=\"wave_study_day\", y=\"longest_string_count\", data=engage_CR_demog_df[engage_CR_demog_df['MitreID'] == u_id], kind=\"bar\")\n",
    "    g.fig.set_size_inches(10,5)\n",
    "    #axes = g.axes\n",
    "    plt.ylim([0,30])\n",
    "    #g.set_ylim(0, 13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_CR_demog_df[engage_CR_demog_df['longest_string_count'] > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get participant ID order when sorted by longest string in the last time bin\n",
    "wave_1_ls = engage_CR_demog_df[engage_CR_demog_df['wave_study_date_bin'] == engage_CR_demog_df['wave_study_date_bin'].unique()[-1]].sort_values('longest_string_count')\n",
    "ls_index = wave_1_ls['MitreID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"MitreID\", y=\"longest_string_count\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', \n",
    "                ci=None, order=ls_index)\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"MitreID\", y=\"ls_7_ratio_bin\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', \n",
    "                ci=None, order=ls_index)\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"MitreID\", y=\"longest_string_ratio_bin\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', \n",
    "                ci=None, order=ls_index)\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"bad_times_high\", y=\"longest_string_count\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin')\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"fatigue\", y=\"longest_string_count\", data=engage_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', order=['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'])\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(engage_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"ocb\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(engage_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"org.deviance\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(engage_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"inter.deviance\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_CR_demog_df['Flexibility'] = engage_CR_demog_df['Flexibility'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(engage_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"Flexibility\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_CR_demog_df['Stress'] = engage_CR_demog_df['Stress'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(engage_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"Stress\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
