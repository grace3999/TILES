{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and clean psychological flexibility EMA data from S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'results_updated' column contains answers to the psychological flexibility survey questions 1-15, need to be processed according to JV instructions as follows:\n",
    "\n",
    "#### instructions from JV for question 1, 3-15\n",
    "\n",
    "relabel “1” as “activity”\n",
    "\n",
    "create ordinal variable “pf_mgt” by computing mean of items 3-15 (range 1-5) – this is the main psychological flexibility score\n",
    "\n",
    "\n",
    "#### instructions from JV for question 2\n",
    "\n",
    "create binary categorical variable “exp_0”.  \n",
    "If question “2” response includes value of 0 or 0.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_1”.  \n",
    "If question “2” response includes value of 1 or 1.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_2”.  \n",
    "If question “2” response includes value of 2 or 2.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_3”.  \n",
    "If question “2” response includes value of 3 or 3.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_4”.  \n",
    "If question “2” response includes value of 4 or 4.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_5”.  \n",
    "If question “2” response includes value of 5 or 5.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_6”.  \n",
    "If question “2” response includes value of 6 or 2.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_7”.  \n",
    "If question “2” response includes value of 7 or 7.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_8”.  \n",
    "If question “2” response includes value of 8 or 8.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_9”.  \n",
    "If question “2” response includes value of 9 or 9.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_10”.  \n",
    "If question “2” response includes value of 10 or 10.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_11”.  \n",
    "If question “2” response includes value of 11 or 11.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_12”.  \n",
    "If question “2” response includes value of 12 or 12.0, code as 1, otherwise code as 0.\n",
    "\n",
    "create binary categorical variable “exp_13”.  \n",
    "If question “2” response includes value of 13 or 13.0, code as 1, otherwise code as 0.\n",
    "\n",
    "\n",
    "create ratio variable “exp_neg” by computing sum of variables: exp_0, exp_2, exp_4, exp_6, exp_8 (range 0-5)\n",
    "\n",
    "create ratio variable “exp_pos” by computing sum of variables: exp_1, exp_3, exp_5, exp_7 (range 0-4)\n",
    "\n",
    "create ratio variable “exp_neut” by computing sum of variables: exp_9, exp_10, exp_11, exp_12, exp_13 (range 0-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PF_S3 = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/TILES/PF_survey_fix/S3_app_surveys_updated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv from S3 bucket; psychologial felxibility EMAs in long form\n",
    "data_PF_S3 = pd.read_csv(path_PF_S3)\n",
    "data_PF_S3 = pd.DataFrame(data = data_PF_S3)\n",
    "print(data_PF_S3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data_PF_S3 shape:\\n', data_PF_S3.shape, '\\n')\n",
    "print('data_PF_S3 unique survey_id shape:\\n', data_PF_S3['survey_id'].unique().shape, '\\n')\n",
    "print('data_PF_S3 unique participant_id shape:\\n', data_PF_S3['participant_id'].unique().shape, '\\n')\n",
    "print('data_PF_S3 unique survey_types:\\n', data_PF_S3['survey_type'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off the psych_flex survey\n",
    "data_PF_S3_PFonly = data_PF_S3[data_PF_S3['survey_type'] == 'psych_flex']\n",
    "print(data_PF_S3_PFonly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each participant should have 50 survey entries\n",
    "data_PF_S3_PFonly_participant_vc = data_PF_S3_PFonly['participant_id'].value_counts()\n",
    "#save this info as csv to share with JV\n",
    "data_PF_S3_PFonly_participant_vc.to_csv('data_PF_S3_PFonly_participant_vc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pf(data):\n",
    "    \n",
    "    #generate dics\n",
    "    qno2_dic = {'activity': np.nan,\n",
    "               'pf_03': np.nan,\n",
    "               'pf_04': np.nan,\n",
    "               'pf_05': np.nan,\n",
    "               'pf_06': np.nan,\n",
    "               'pf_07': np.nan,\n",
    "               'pf_08': np.nan,\n",
    "               'pf_09': np.nan,\n",
    "               'pf_10': np.nan,\n",
    "               'pf_11': np.nan,\n",
    "               'pf_12': np.nan,\n",
    "               'pf_13': np.nan,\n",
    "               'pf_14': np.nan,\n",
    "               'pf_15': np.nan}\n",
    "        \n",
    "    q2_dic = {'exp_0': 0,\n",
    "              'exp_1': 0, \n",
    "              'exp_2': 0,\n",
    "              'exp_3': 0,\n",
    "              'exp_4': 0,\n",
    "              'exp_5': 0,\n",
    "              'exp_6': 0,\n",
    "              'exp_7': 0,\n",
    "              'exp_8': 0,\n",
    "              'exp_9': 0,\n",
    "              'exp_10': 0,\n",
    "              'exp_11': 0,\n",
    "              'exp_12': 0,\n",
    "              'exp_13': 0,\n",
    "              'exp_neg': 0,\n",
    "              'exp_pos': 0,\n",
    "              'exp_neut': 0}\n",
    "    \n",
    "    #determine if they answered the survey, if they did then process and update qno2_dic and q2_dic\n",
    "    try:\n",
    "        type(data) == str\n",
    "    \n",
    "        #create dic from entry\n",
    "        dic = eval(data)\n",
    "        \n",
    "        #process question #2 first, consists of 1-13 possible entries \n",
    "        try: #not everyone answered q2\n",
    "            if type(dic['2']) == int: #if only have 1 entry for q2\n",
    "                x = dic['2']\n",
    "                q2_dic[f'exp_{x}'] = 1\n",
    "            else: #for multiple entries for q2\n",
    "                for item in dic['2']:\n",
    "                    item = int(item)\n",
    "                    q2_dic[f'exp_{item}'] = 1\n",
    "            #use entries to compute three different numbers (see above for more details)\n",
    "            q2_dic['exp_neg'] = q2_dic['exp_0'] + q2_dic['exp_2'] + q2_dic['exp_4'] + q2_dic['exp_6'] + q2_dic['exp_8']\n",
    "            q2_dic['exp_pos'] = q2_dic['exp_1'] + q2_dic['exp_3'] + q2_dic['exp_5'] + q2_dic['exp_7']\n",
    "            q2_dic['exp_neut'] = q2_dic['exp_9'] + q2_dic['exp_10'] + q2_dic['exp_11'] + q2_dic['exp_12'] + q2_dic['exp_13']\n",
    "            \n",
    "        except:\n",
    "            #so we can find the surveys where q2 wasn't answered at all\n",
    "            q2_dic = {'exp_0': np.nan,\n",
    "              'exp_1': np.nan, \n",
    "              'exp_2': np.nan,\n",
    "              'exp_3': np.nan,\n",
    "              'exp_4': np.nan,\n",
    "              'exp_5': np.nan,\n",
    "              'exp_6': np.nan,\n",
    "              'exp_7': np.nan,\n",
    "              'exp_8': np.nan,\n",
    "              'exp_9': np.nan,\n",
    "              'exp_10': np.nan,\n",
    "              'exp_11': np.nan,\n",
    "              'exp_12': np.nan,\n",
    "              'exp_13': np.nan,\n",
    "              'exp_neg': np.nan,\n",
    "              'exp_pos': np.nan,\n",
    "              'exp_neut': np.nan}\n",
    "        \n",
    "        #process questions 1 and 3-15\n",
    "        try: #not everyone answered all questions\n",
    "            qno2_dic['activity'] = dic['1']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_03'] = dic['3']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_04'] = dic['4']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_05'] = dic['5']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_06'] = dic['6']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_07'] = dic['7']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_08'] = dic['8']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_09'] = dic['9']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_10'] = dic['10']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_11'] = dic['11']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_12'] = dic['12']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_13'] = dic['13']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_14'] = dic['14']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            qno2_dic['pf_15'] = dic['15']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #create dataframes\n",
    "    pf_df_q2 = pd.DataFrame.from_dict(q2_dic, orient='index').T\n",
    "    \n",
    "    pf_df_qno2 = pd.DataFrame.from_dict(qno2_dic, orient='index').T\n",
    "    pf_df_qno2 = pf_df_qno2.reindex(sorted(pf_df_qno2.columns), axis=1)\n",
    "    \n",
    "    #see instructions above for more details\n",
    "    pf_df_qno2.rename({'pf_01': 'activity'}, axis='columns', inplace=True)\n",
    "    pf_df_qno2['pf_mgt'] = pf_df_qno2.loc[:, 'pf_03':].mean(axis = 1)\n",
    "\n",
    "    pf_df = pd.concat([pf_df_qno2, pf_df_q2], axis = 1)\n",
    "    \n",
    "    return pf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame that will contain data_PF_S3_PFonly and the processed pf data for each entry\n",
    "col_names = ['activity', 'pf_03', 'pf_04', 'pf_05', 'pf_06', 'pf_07', 'pf_08', 'pf_09', 'pf_10', 'pf_11', 'pf_12', 'pf_13', 'pf_14', 'pf_15', 'pf_mgt', 'exp_0', 'exp_1', 'exp_2', 'exp_3', 'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10', 'exp_11', 'exp_12', 'exp_13', 'exp_neg', 'exp_pos', 'exp_neut']\n",
    "pf_final = pd.DataFrame(columns=col_names, index=data_PF_S3_PFonly.index)\n",
    "pf_final = pd.concat([data_PF_S3_PFonly, pf_final], axis = 1)\n",
    "\n",
    "for index, row in data_PF_S3_PFonly.iterrows():\n",
    "    df = process_pf(row['results_updated'])\n",
    "    pf_final.loc[index, col_names] = df.values[0]\n",
    "\n",
    "pf_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this info as csv to use for subsequent analysis and to share with JV and rest of group\n",
    "pf_final.to_csv('pf_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
