{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careless responder feature engineering and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from itertools import groupby\n",
    "import datetime as dt\n",
    "import scipy as sp\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/TILES/final_data/final_data_complete.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv containing data from all surveys\n",
    "data = pd.read_pickle(data_path)\n",
    "data = pd.DataFrame(data = data)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('Original data shape:\\n', data.shape, '\\n')\n",
    "#ensure no replicate ID (212 participants in study)\n",
    "print('Original data unique IDs:\\n', data['ParticipantID'].unique().shape, '\\n')\n",
    "#ensure no replicate ID (212 participants in study)\n",
    "print('Original data unique IDs:\\n', data['MitreID'].unique().shape, '\\n')\n",
    "#how much missing data is there?\n",
    "print('Original data missing value counts:\\n', data.isnull().sum(), '\\n')\n",
    "#what is the data type of each column?\n",
    "print('Original data data types:\\n', data.info(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be 71\n",
    "len(data['wave_study_day'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create study date bins\n",
    "data['wave_study_date_bin'] = pd.cut(data['wave_study_day'], 5)\n",
    "data['wave_study_date_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and clustering on Engage surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes for CR features for Engage surveys\n",
    "\n",
    "Context question\n",
    "- Semantic Antonyms\n",
    "    - if context1 = home (0), then context2 ≠ work and work related (0)\n",
    "    - if context1 = work (1), then context2 ≠ leisure sports (4), household activities (7), org/civic (11)\n",
    "- Semantic Synonyms\n",
    "    - if context1 = work (1), then context2 most likely work and work related (0)\n",
    "    - If context1 = vehicle (4), then context2 most likely travel or commute (12)\n",
    "- Internal consistency\n",
    "    - if context1 = 5 (other) then should have a write in\n",
    "    - if context2 = 13 (other) then should have a write in\n",
    "\n",
    "Longstring\n",
    "- All questions use same scale (1=not at all, 7=very much), but there are 5 different constructs assessed\n",
    "\n",
    "Semantic consistency\n",
    "- Internal consistency (within construct) should be greater than consistency across constructs\n",
    "\n",
    "Semantic synonyms \n",
    "- not applicable \n",
    "\n",
    "Semantic antonyms\n",
    "- Hindrance stressors should be negatively correlated with support \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off completed engage and related columns\n",
    "engage_only = data[(data['survey_type'] == 'engage_psycap') & (data['completed'] == 1.0)]\n",
    "\n",
    "print(engage_only.shape)\n",
    "engage_only['ParticipantID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context related CR features\n",
    "        \n",
    "context_homevsworking = []\n",
    "context_workvsactivities = []\n",
    "context_workvswork = []\n",
    "context_drivevsdrive = []\n",
    "write_in_location = []\n",
    "write_in_activity = []\n",
    "hinderance_vs_support = []\n",
    "\n",
    "for index, row in engage_only.iterrows():\n",
    "    \n",
    "    #if at home should not be working\n",
    "    if (row['location_num'] == 0) & (row['activity_num'] == 0):\n",
    "        context_homevsworking.append(1)\n",
    "    else:\n",
    "        context_homevsworking.append(0)\n",
    "        \n",
    "    #if at work should not be playing sports, household activities, civic duties\n",
    "    if (row['location_num'] == 1) & ((row['activity_num'] == 4) | (row['activity_num'] == 7) | (row['activity_num'] == 11)):\n",
    "        context_workvsactivities.append(1)\n",
    "    else:\n",
    "        context_workvsactivities.append(0)\n",
    "    \n",
    "    #if at work should be working\n",
    "    if (row['location_num'] == 1) & (row['activity_num'] != 0):\n",
    "        context_workvswork.append(1)\n",
    "    else:\n",
    "        context_workvswork.append(0)\n",
    "        \n",
    "    #if at vehicle should be driving/travel    \n",
    "    if (row['location_num'] == 4) & (row['activity_num'] != 12):\n",
    "        context_drivevsdrive.append(1)\n",
    "    else:\n",
    "        context_drivevsdrive.append(0)\n",
    "    \n",
    "    #if put other then should have write in\n",
    "    if row['location_num'] == 5:\n",
    "        write_in_location.append(1)\n",
    "    else:\n",
    "        write_in_location.append(0)\n",
    "        \n",
    "    if (row['activity_num'] == 13):\n",
    "        write_in_activity.append(1)\n",
    "    else:\n",
    "        write_in_activity.append(0)\n",
    "        \n",
    "    #Hindrance stressors should be negatively correlated with support\n",
    "    num = np.std([row['support_mgt'], row['hindrance_mgt']])\n",
    "    hinderance_vs_support.append(abs(num))\n",
    "\n",
    "#context checks\n",
    "engage_only['context_homevsworking'] = context_homevsworking\n",
    "engage_only['context_workvsactivities'] = context_workvsactivities\n",
    "engage_only['context_workvswork'] = context_workvswork\n",
    "engage_only['context_drivevsdrive'] = context_drivevsdrive\n",
    "\n",
    "engage_only['write_in_location'] = write_in_location\n",
    "engage_only['write_in_activity'] = write_in_activity\n",
    "engage_only['hinderance_vs_support'] = hinderance_vs_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long string analysis (e.g. max length of same number answered for engage_3:engage_29)\n",
    "#create features related to long string analysis (feature of how long the string is and feature of what the string consisted of)\n",
    "\n",
    "max_strings = []\n",
    "max_answers = []\n",
    "\n",
    "for index, row in engage_only.iterrows():\n",
    "    \n",
    "    groups = groupby(row['engage_3':'engage_29'])\n",
    "    result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "\n",
    "    max_pair = max(result, key=lambda x:x[1])\n",
    "    max_string_length = max_pair[1]\n",
    "    max_answer = max_pair[0]\n",
    "\n",
    "    max_strings.append(max_string_length)\n",
    "    \n",
    "    max_answers.append(max_answer)\n",
    "    \n",
    "engage_only['longest_string_count'] = max_strings\n",
    "engage_only['longest_string_answer'] = max_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeded skew and kurtosis (trying to deal with 0 skew of all same answer vs normally distributed answers)\n",
    "std_seeded = []\n",
    "skew_seeded = []\n",
    "kurt_seeded = []\n",
    "\n",
    "for index, row in engage_only.iterrows():\n",
    "    num_std = np.std(np.append(row.loc['engage_3':'engage_29'].dropna().values, 0.0))\n",
    "    std_seeded.append(num_std)\n",
    "    num_skew = sp.stats.skew(np.append(row.loc['engage_3':'engage_29'].dropna().values, 0.0))\n",
    "    skew_seeded.append(num_skew)\n",
    "    num_kurt = sp.stats.kurtosis(np.append(row.loc['engage_3':'engage_29'].dropna().values, 0.0))\n",
    "    kurt_seeded.append(num_kurt)\n",
    "    \n",
    "engage_only['std_seeded'] = std_seeded    \n",
    "engage_only['skew_seeded'] = skew_seeded\n",
    "engage_only['kurt_seeded'] = kurt_seeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is surevy response skew\n",
    "engage_only['std'] = engage_only.loc[:, 'engage_3':'engage_29'].std(axis=1)\n",
    "engage_only['skew'] = engage_only.loc[:, 'engage_3':'engage_29'].skew(axis=1)\n",
    "engage_only['kurtosis'] = engage_only.loc[:, 'engage_3':'engage_29'].kurtosis(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_only.dropna(subset=['hinderance_vs_support'], inplace=True)\n",
    "engage_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz relationship and correlation across possible features\n",
    "potential_features = ['longest_string_count', 'longest_string_answer', 'std_seeded', 'skew_seeded', 'kurt_seeded', \n",
    "                      'std', 'skew', 'kurtosis', 'time_to_complete', 'hinderance_vs_support', \n",
    "                      'context_homevsworking', 'context_workvsactivities', 'context_workvswork', 'context_drivevsdrive', \n",
    "                      'write_in_location', 'write_in_activity']\n",
    "potential_features_cont = ['hinderance_vs_support', 'longest_string_count', 'longest_string_answer', \n",
    "                           'std_seeded', 'skew_seeded', 'kurt_seeded', 'std', 'skew', 'kurtosis', 'time_to_complete']\n",
    "potential_features_binary = ['context_homevsworking', 'context_workvsactivities', 'context_workvswork', \n",
    "                             'context_drivevsdrive', 'write_in_location', 'write_in_activity']\n",
    "\n",
    "engage_only_features_potential = engage_only[potential_features]\n",
    "engage_only_features_cont = engage_only[potential_features_cont]\n",
    "engage_only_features_potential.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features_cont:\n",
    "    sns.jointplot(engage_only_features_potential['longest_string_count'], engage_only_features_potential[feature], kind='hex')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features_binary:\n",
    "    print(engage_only[feature].value_counts())\n",
    "    sns.countplot(x='longest_string_count', hue=feature, data=engage_only_features_potential)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(engage_only[potential_features_cont], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_only_features = engage_only[['MitreID', 'hinderance_vs_support', 'longest_string_count', 'skew_seeded', 'kurt_seeded']]\n",
    "engage_only_features.set_index('MitreID', inplace=True)\n",
    "engage_only_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "engage_survey_features_scaled = scaler.fit_transform(engage_only_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=1)\n",
    "    km_ss.fit(engage_survey_features_scaled)\n",
    "    scores.append(silhouette_score(engage_survey_features_scaled, km_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.title('PF kmeans at survey level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_km_survey = KMeans(n_clusters=2,random_state=1234)\n",
    "engage_km_survey.fit(engage_survey_features_scaled)\n",
    "print(silhouette_score(engage_survey_features_scaled, engage_km_survey.labels_))\n",
    "\n",
    "engage_only_features['kmeans_scaled_survey'] = [label for label in engage_km_survey.labels_ ]\n",
    "engage_only_features_cont['kmeans_scaled_survey'] = [label for label in engage_km_survey.labels_ ]\n",
    "engage_only['kmeans_scaled_survey'] = [label for label in engage_km_survey.labels_ ]\n",
    "\n",
    "engage_only['kmeans_scaled_survey'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(engage_only_features_cont, hue = 'kmeans_scaled_survey', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features:\n",
    "    sns.barplot(x='kmeans_scaled_survey', y=feature, data=engage_only)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features:\n",
    "    sns.barplot(x='longest_string_count', y=feature, hue='kmeans_scaled_survey', data=engage_only)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features_binary:\n",
    "    print(engage_only.groupby(\"kmeans_scaled_survey\")[feature].value_counts())\n",
    "    sns.countplot(x='longest_string_count', hue=feature, data=engage_only_features_potential)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engage_only.groupby(['MitreID', 'kmeans_scaled_survey'])['ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cluster 1 % to final data\n",
    "participants = data['MitreID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    if part in engage_only_features.index:\n",
    "        perc = engage_only_features[(engage_only_features.index == part) & (engage_only_features['kmeans_scaled_survey'] == 1)].shape[0] / engage_only_features[engage_only_features.index == part].shape[0]\n",
    "\n",
    "        data.loc[data['MitreID'] == part, 'engage_CR_perc'] = perc\n",
    "        engage_only.loc[engage_only['MitreID'] == part, 'engage_CR_perc'] = perc\n",
    "    \n",
    "    else:\n",
    "        data.loc[data['MitreID'] == part, 'engage_CR_perc'] = np.nan\n",
    "        engage_only.loc[engage_only['MitreID'] == part, 'engage_CR_perc'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='wave_study_date_bin', hue='kmeans_scaled_survey', data=engage_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='MitreID', y='engage_CR_perc', data=engage_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = engage_only['MitreID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    data_part = engage_only[engage_only['MitreID'] == part]\n",
    "    sns.countplot(x='wave_study_day', hue='kmeans_scaled_survey', data=data_part)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and clustering on PF surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes for CR features for Psych Flex\n",
    "\n",
    "Should have answered every question\n",
    "\n",
    "Longstring\n",
    "- Legitimate longstrings of  ≥ 8 are unlikely for response “5”\n",
    "    - make column with longest string\n",
    "    - make column with number that longest string consisted of\n",
    "\n",
    "Semantic consistency\n",
    "- Legitimate scores of pf_mgt=5 are almost impossible\n",
    "\n",
    "Semantic antonyms\n",
    "- Not applicable\n",
    "\n",
    "Semantic synonyms \n",
    "- not applicable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off completed PF and related columns\n",
    "psych_flex_only = data[(data['survey_type'] == 'psych_flex') & (data['completed'] == 1.0)]\n",
    "\n",
    "print(psych_flex_only.shape)\n",
    "psych_flex_only['ParticipantID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long string analysis (e.g. max length of same number answered for pf_03:pf_15)\n",
    "#create features related to long string analysis (feature of how long the string is and feature of what the string consisted of)\n",
    "\n",
    "max_strings = []\n",
    "max_answers = []\n",
    "\n",
    "for index, row in psych_flex_only.iterrows():\n",
    "    \n",
    "    groups = groupby(row['pf_03':'pf_15'])\n",
    "    result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "\n",
    "    max_pair = max(result, key=lambda x:x[1])\n",
    "    max_string_length = max_pair[1]\n",
    "    max_answer = max_pair[0]\n",
    "\n",
    "    max_strings.append(max_string_length)\n",
    "    \n",
    "    max_answers.append(max_answer)\n",
    "    \n",
    "psych_flex_only['longest_string_count'] = max_strings\n",
    "psych_flex_only['longest_string_answer'] = max_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeded skew and kurtosis (trying to deal with 0 skew of all same answer vs normally distributed answers)\n",
    "std_seeded = []\n",
    "skew_seeded = []\n",
    "kurt_seeded = []\n",
    "\n",
    "for index, row in psych_flex_only.iterrows():\n",
    "    \n",
    "    try:\n",
    "        num_std = np.std(np.append(row.loc['pf_03':'pf_15'].dropna().values, 0.0))\n",
    "        std_seeded.append(num_std)\n",
    "    except:\n",
    "        std_seeded.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        num_skew = sp.stats.skew(np.append(row.loc['pf_03':'pf_15'].dropna().values, 0.0))\n",
    "        skew_seeded.append(num_skew)\n",
    "    except:\n",
    "        skew_seeded.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        num_kurt = sp.stats.kurtosis(np.append(row.loc['pf_03':'pf_15'].dropna().values, 0.0))\n",
    "        kurt_seeded.append(num_kurt)\n",
    "    except:\n",
    "        kurt_seeded.append(np.nan)\n",
    "    \n",
    "psych_flex_only['std_seeded'] = std_seeded    \n",
    "psych_flex_only['skew_seeded'] = skew_seeded\n",
    "psych_flex_only['kurt_seeded'] = kurt_seeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features without seed\n",
    "psych_flex_only['std'] = psych_flex_only.loc[:, 'pf_03':'pf_15'].std(axis=1)\n",
    "psych_flex_only['skew'] = psych_flex_only.loc[:, 'pf_03':'pf_15'].skew(axis=1)\n",
    "psych_flex_only['kurtosis'] = psych_flex_only.loc[:, 'pf_03':'pf_15'].kurtosis(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_flex_only.dropna(subset=['kurtosis', 'skew_seeded'], inplace=True)\n",
    "psych_flex_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz relationship and correlation across possible features\n",
    "potential_features = ['pf_mgt', 'longest_string_count', 'longest_string_answer', 'std_seeded', 'skew_seeded', 'kurt_seeded', \n",
    "                      'std', 'skew', 'kurtosis', 'time_to_complete', 'exp_neg', 'exp_pos', 'exp_neut']\n",
    "\n",
    "psych_flex_only_features_potential = psych_flex_only[potential_features]\n",
    "psych_flex_only_features_potential.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features:\n",
    "    sns.jointplot(psych_flex_only_features_potential['longest_string_count'], psych_flex_only_features_potential[feature], kind='hex')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(psych_flex_only_features_potential, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_flex_only_features = psych_flex_only[['MitreID', 'longest_string_count', 'skew_seeded', 'kurt_seeded']]\n",
    "psych_flex_only_features.set_index('MitreID', inplace=True)\n",
    "psych_flex_only_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "PF_survey_features_scaled = scaler.fit_transform(psych_flex_only_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=1)\n",
    "    km_ss.fit(PF_survey_features_scaled)\n",
    "    scores.append(silhouette_score(PF_survey_features_scaled, km_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.title('PF kmeans at survey level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_km_survey = KMeans(n_clusters=2,random_state=1234)\n",
    "PF_km_survey.fit(PF_survey_features_scaled)\n",
    "print(silhouette_score(PF_survey_features_scaled, PF_km_survey.labels_))\n",
    "\n",
    "psych_flex_only_features_potential['kmeans_scaled_survey'] = [label for label in PF_km_survey.labels_ ]\n",
    "psych_flex_only_features['kmeans_scaled_survey'] = [label for label in PF_km_survey.labels_ ]\n",
    "psych_flex_only['kmeans_scaled_survey'] = [label for label in PF_km_survey.labels_ ]\n",
    "\n",
    "psych_flex_only['kmeans_scaled_survey'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in potential_features:\n",
    "    sns.barplot(x='kmeans_scaled_survey', y=feature, data=psych_flex_only)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(psych_flex_only_features_potential, hue = 'kmeans_scaled_survey', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cluster 1 % to final data\n",
    "participants = data['MitreID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    if part in psych_flex_only_features.index:\n",
    "        perc = psych_flex_only_features[(psych_flex_only_features.index == part) & (psych_flex_only_features['kmeans_scaled_survey'] == 0)].shape[0] / psych_flex_only_features[psych_flex_only_features.index == part].shape[0]\n",
    "\n",
    "        data.loc[data['MitreID'] == part, 'pf_CR_perc'] = perc\n",
    "        psych_flex_only.loc[psych_flex_only['MitreID'] == part, 'pf_CR_perc'] = perc\n",
    "    \n",
    "    else:\n",
    "        data.loc[data['MitreID'] == part, 'pf_CR_perc'] = np.nan\n",
    "        psych_flex_only.loc[psych_flex_only['MitreID'] == part, 'pf_CR_perc'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='wave_study_date_bin', hue='kmeans_scaled_survey', data=psych_flex_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='MitreID', y='pf_CR_perc', data=psych_flex_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='pf_CR_perc', y='engage_CR_perc', data=data, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "participants = psych_flex_only['MitreID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    print(part)\n",
    "    data_part = psych_flex_only[psych_flex_only['MitreID'] == part]\n",
    "    sns.countplot(x='wave_study_day', hue='kmeans_scaled_survey', data=data_part)\n",
    "    plt.show()\n",
    "    data_part = engage_only[engage_only['MitreID'] == part]\n",
    "    sns.countplot(x='wave_study_day', hue='kmeans_scaled_survey', data=data_part)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and clustering on Mitre surveys: Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes for CR features for Jobs\n",
    "\n",
    "Context question (context 2 = activity, context 3 = location)\n",
    "- Semantic Antonyms\n",
    "    - if context3 = home (1), then context2 ≠ work and work related (1)\n",
    "    - if context3 = work (2), then context2 ≠ leisure sports (3), household activities (6), org/civic (10)\n",
    "- Semantic Synonyms\n",
    "    - if context3 = work (2), then context2 most likely work and work related (1)\n",
    "    - If context3 = vehicle (5), then context2 most likely travel or commute (11)\n",
    "\n",
    "Affect/Anxiety/Stress\n",
    "- Longstrings\n",
    "    - All questions use same scale\n",
    "- Semantic antonyms\n",
    "    - Positive block (pan1-5) should be negatively correlated with negative block (pan6-10)\n",
    "\n",
    "Task Perfomrance\n",
    "- Longstrings\n",
    "    - IRB questions use same scale\n",
    "    - dalal questions use same scale\n",
    "- Consistency\n",
    "    - irb2, irb3, irb4 should be negatively correlated with irb6 and irb7\n",
    "    - itp1, itp2, itp3 should be negatively correlated with irb6 and irb7\n",
    "    - dalal1-8 should be negatively correlated with dalal9-dalal16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context related CR features\n",
    "        \n",
    "context_homevsworking = []\n",
    "context_workvsactivities = []\n",
    "context_workvswork = []\n",
    "context_drivevsdrive = []\n",
    "\n",
    "affect_check = []\n",
    "\n",
    "for index, row in job_only.iterrows():\n",
    "    \n",
    "    #if at home should not be working\n",
    "    if (row['context3'] == 1) & (row['context2'] == 1):\n",
    "        context_homevsworking.append(1)\n",
    "    else:\n",
    "        context_homevsworking.append(0)\n",
    "        \n",
    "    #if at work should not be playing sports, household activities, civic duties\n",
    "    if (row['context3'] == 2) & ((row['context2'] == 3) | (row['activity_num'] == 6) | (row['activity_num'] == 10)):\n",
    "        context_workvsactivities.append(1)\n",
    "    else:\n",
    "        context_workvsactivities.append(0)\n",
    "    \n",
    "    #if at work should be working\n",
    "    if (row['context3'] == 2) & (row['context2'] != 1):\n",
    "        context_workvswork.append(1)\n",
    "    else:\n",
    "        context_workvswork.append(0)\n",
    "        \n",
    "    #if at vehicle should be driving/travel    \n",
    "    if (row['context3'] == 5) & (row['context2'] != 11):\n",
    "        context_drivevsdrive.append(1)\n",
    "    else:\n",
    "        context_drivevsdrive.append(0)\n",
    "    \n",
    "\n",
    "        \n",
    "    #Positive block (pan1-5) should be negatively correlated with negative block (pan6-10)\n",
    "    pos_ave = row['pand1':'pand5'].mean()\n",
    "    neg_ave = row['pand6':'pand10'].mean()\n",
    "    num = np.std([pos_ave, neg_ave])\n",
    "    affect_check.append(abs(num))\n",
    "    \n",
    "    #irb2, irb3, irb4 should be negatively correlated with irb6 and irb7\n",
    "    #itp1, itp2, itp3 should be negatively correlated with irb6 and irb7\n",
    "    #dalal1-8 should be negatively correlated with dalal9-dalal16\n",
    "\n",
    "#context checks\n",
    "job_only['context_homevsworking'] = context_homevsworking\n",
    "job_only['context_workvsactivities'] = context_workvsactivities\n",
    "job_only['context_workvswork'] = context_workvswork\n",
    "job_only['context_drivevsdrive'] = context_drivevsdrive\n",
    "\n",
    "\n",
    "job_only['affect_check'] = affect_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long string analysis (e.g. max length of same number answered for pf_03:pf_15)\n",
    "#create features related to long string analysis (feature of how long the string is and feature of what the string consisted of)\n",
    "\n",
    "max_strings = []\n",
    "max_answers = []\n",
    "\n",
    "for index, row in psych_flex_only.iterrows():\n",
    "    \n",
    "    groups = groupby(row['pf_03':'pf_15'])\n",
    "    result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "\n",
    "    max_pair = max(result, key=lambda x:x[1])\n",
    "    max_string_length = max_pair[1]\n",
    "    max_answer = max_pair[0]\n",
    "\n",
    "    max_strings.append(max_string_length)\n",
    "    \n",
    "    max_answers.append(max_answer)\n",
    "    \n",
    "psych_flex_only['longest_string_count'] = max_strings\n",
    "psych_flex_only['longest_string_answer'] = max_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off completed job and related columns\n",
    "job_only = data[(data['survey_type'] == 'job')]\n",
    "\n",
    "print(job_only.shape)\n",
    "job_only['ParticipantID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_only['dalal16'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
