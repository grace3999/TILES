{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careless responder feature engineering and analysis (inital focus on psych_flex survey only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from itertools import groupby\n",
    "import datetime as dt\n",
    "from numpy import median\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/TILES/final_data/data_final_combined.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv containing participant info\n",
    "data = pd.read_pickle(data_path)\n",
    "data = pd.DataFrame(data = data)\n",
    "#data_PF.reset_index(inplace=True)\n",
    "\n",
    "print('Original data shape:\\n', data.shape, '\\n')\n",
    "#ensure no replicate ID (212 participants in study)\n",
    "print('Original data unique IDs:\\n', data['ParticipantID'].unique().shape, '\\n')\n",
    "#ensure no replicate ID (212 participants in study)\n",
    "print('Original data unique IDs:\\n', data['MitreID'].unique().shape, '\\n')\n",
    "#how much missing data is there?\n",
    "print('Original data missing value counts:\\n', data.isnull().sum(), '\\n')\n",
    "#what is the data type of each column?\n",
    "print('Original data data types:\\n', data.info(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be 71\n",
    "len(data['wave_study_day'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes for CR features for Psych Flex\n",
    "\n",
    "Should have answered every question\n",
    "\n",
    "Longstring\n",
    "- Legitimate longstrings of  ≥ 8 are unlikely for response “5”\n",
    "    - make column with longest string\n",
    "    - make column with number that longest string consisted of\n",
    "\n",
    "Semantic consistency\n",
    "- Legitimate scores of pf_mgt=5 are almost impossible\n",
    "\n",
    "Semantic antonyms\n",
    "- Not applicable\n",
    "\n",
    "Semantic synonyms \n",
    "- not applicable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off completed PF and related columns\n",
    "psych_flex_only = data[(data['survey_type'] == 'psych_flex') & (data['completed'] == 1.0)]\n",
    "psych_flex_only = psych_flex_only[['index', 'MitreID', 'ParticipantID', 'PrimaryUnit', 'SmartPhone',\n",
    "       'Sex', 'Shift', 'Wave', 'survey_id', 'survey_type', 'date_time',\n",
    "       'date', 'time', 'Timesent', 'completed', 'start_delay',\n",
    "       'time_to_complete', 'activity_num', 'location_num',\n",
    "       'activity', 'pf_03', 'pf_04', 'pf_05', 'pf_06',\n",
    "       'pf_07', 'pf_08', 'pf_09', 'pf_10', 'pf_11', 'pf_12', 'pf_13',\n",
    "       'pf_14', 'pf_15', 'pf_mgt', 'exp_0', 'exp_1', 'exp_2', 'exp_3',\n",
    "       'exp_4', 'exp_5', 'exp_6', 'exp_7', 'exp_8', 'exp_9', 'exp_10',\n",
    "       'exp_11', 'exp_12', 'exp_13', 'exp_neg', 'exp_pos', 'exp_neut',\n",
    "       'wave_study_date', 'wave_study_day',\n",
    "       'survey_count', 'day_of_week', 'working', 'at_work']]\n",
    "\n",
    "psych_flex_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create study date bins\n",
    "psych_flex_only['wave_study_date_bin'] = pd.cut(psych_flex_only['wave_study_day'], 5)\n",
    "psych_flex_only['wave_study_date_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is count of missing values from survey\n",
    "psych_flex_only.loc[psych_flex_only.loc[:, 'activity':'pf_mgt'].isnull().sum(axis=1) > 0, 'missing_values'] = psych_flex_only.loc[:, 'activity':'pf_mgt'].isnull().sum(axis=1)\n",
    "psych_flex_only.loc[psych_flex_only.loc[:, 'activity':'pf_mgt'].isnull().sum(axis=1) == 0, 'missing_values'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is number of surveys that were not completed\n",
    "\n",
    "part_id = psych_flex_only['ParticipantID'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    missing = 49 - psych_flex_only[psych_flex_only['ParticipantID'] == participant]['survey_count'].max()\n",
    "    psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant), 'uncompleted'] = missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is number of surveys that were not completed within wave study date bin\n",
    "\n",
    "part_id = psych_flex_only['ParticipantID'].unique()\n",
    "day_bins = psych_flex_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    for unique_bin in day_bins:\n",
    "        missing = 10 - psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin)].shape[0]\n",
    "        if missing < 0:\n",
    "            missing = 0\n",
    "        psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin), 'uncompleted_day_bin'] = missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long string analysis (e.g. max length of same number answered for pf_03:pf_15)\n",
    "#create features related to long string analysis (feature of how long the string is and feature of what the string consisted of)\n",
    "\n",
    "max_strings = []\n",
    "max_answers = []\n",
    "\n",
    "for index, row in psych_flex_only.iterrows():\n",
    "    \n",
    "    groups = groupby(row['pf_03':'pf_15'])\n",
    "    result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "\n",
    "    max_pair = max(result, key=lambda x:x[1])\n",
    "    max_string_length = max_pair[1]\n",
    "    max_answer = max_pair[0]\n",
    "\n",
    "    max_strings.append(max_string_length)\n",
    "    \n",
    "    max_answers.append(max_answer)\n",
    "\n",
    "psych_flex_only['longest_string_count'] = max_strings\n",
    "psych_flex_only['longest_string_answer'] = max_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of average longstring during first day bin to average longstring during last time bin\n",
    "\n",
    "part_id = psych_flex_only['ParticipantID'].unique()\n",
    "day_bins = psych_flex_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    string_1 = psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == day_bins[0])]['longest_string_count'].mean() \n",
    "    string_2 = psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == day_bins[-1])]['longest_string_count'].mean()\n",
    "\n",
    "    psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant), 'longest_string_ratio'] = string_2 / string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of average longstring during current bin to average longstring during last time bin\n",
    "\n",
    "part_id = psych_flex_only['ParticipantID'].unique()\n",
    "day_bins = psych_flex_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    for unique_bin in day_bins:\n",
    "        string_1 = psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin)]['longest_string_count'].mean() \n",
    "        string_2 = psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == day_bins[-1])]['longest_string_count'].mean()\n",
    "\n",
    "        psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin), 'longest_string_ratio_bin'] = string_2 / string_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of number of longstrings over 7 to total number of surveys taken\n",
    "\n",
    "part_id = psych_flex_only['ParticipantID'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    count_over_7 = psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['longest_string_count'] >= 8)].shape[0]\n",
    "    \n",
    "    psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant), 'ls_7_ratio'] = count_over_7 / psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is ratio of number of longstrings over 7 during current bin to total number of surveys taken for that bin\n",
    "\n",
    "part_id = psych_flex_only['ParticipantID'].unique()\n",
    "day_bins = psych_flex_only['wave_study_date_bin'].unique()\n",
    "\n",
    "for participant in part_id:\n",
    "    for unique_bin in day_bins:\n",
    "        count_over_7 = psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) \n",
    "                                           & (psych_flex_only['longest_string_count'] >= 8) \n",
    "                                           & (psych_flex_only['wave_study_date_bin'] == unique_bin)].shape[0]\n",
    "        try:\n",
    "            psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin), 'ls_7_ratio_bin'] = count_over_7 / psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin)].shape[0]\n",
    "        except:\n",
    "            psych_flex_only.loc[(psych_flex_only['ParticipantID'] == participant) & (psych_flex_only['wave_study_date_bin'] == unique_bin), 'ls_7_ratio_bin'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature that is binary for if time_to_complete is very short or long (0 is neither)\n",
    "bad_times_low = []\n",
    "bad_times_high = []\n",
    "\n",
    "for index, row in psych_flex_only.iterrows():\n",
    "    \n",
    "    if (row['time_to_complete'] <= 20): \n",
    "        bad_times_low.append(1)\n",
    "    else:\n",
    "        bad_times_low.append(0)\n",
    "    \n",
    "    if (row['time_to_complete'] > 1200): \n",
    "        bad_times_high.append(1)\n",
    "    else:\n",
    "        bad_times_high.append(0)\n",
    "\n",
    "psych_flex_only['bad_times_low'] = bad_times_low\n",
    "psych_flex_only['bad_times_high'] = bad_times_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_flex_CR = psych_flex_only[['MitreID', 'ParticipantID', 'PrimaryUnit', 'SmartPhone',\n",
    "       'Sex', 'Shift', 'Wave', 'start_delay',\n",
    "       'time_to_complete', 'activity_num', 'pf_mgt',\n",
    "       'exp_neg', 'exp_pos', 'exp_neut',\n",
    "       'wave_study_day', 'survey_count', 'day_of_week', 'working',\n",
    "       'wave_study_date_bin', 'missing_values', 'uncompleted',\n",
    "       'uncompleted_day_bin', 'longest_string_count',\n",
    "       'longest_string_answer', 'longest_string_ratio',\n",
    "       'longest_string_ratio_bin', 'bad_times_low', 'bad_times_high', 'ls_7_ratio', 'ls_7_ratio_bin']]\n",
    "\n",
    "psych_flex_CR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_demog_prepost = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/TILES/final_data/Demog, PRE, PST survey composites.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data_demog_prepost, contains demographic information and pre/post questionaires\n",
    "data_demog_prepost = pd.read_csv(path_demog_prepost)\n",
    "data_demog_prepost = pd.DataFrame(data = data_demog_prepost)\n",
    "print('Original demog_prepost shape:\\n', data_demog_prepost.shape, '\\n')\n",
    "#replace blnaks with nans\n",
    "data_demog_prepost = data_demog_prepost.replace(' ', np.nan)\n",
    "#ensure no replicate ID (eg one row per participant in study)\n",
    "print('Original demog_prepost unique IDs:\\n', data_demog_prepost['ID'].unique().shape, '\\n')\n",
    "print('Original demog_prepost missing value couts:\\n', data_demog_prepost.isnull().sum(), '\\n')\n",
    "print('Original demog_prepost data types:\\n', data_demog_prepost.info(), '\\n')\n",
    "data_demog_prepost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the information contained in data_demog_prepost to psych_flex_CR\n",
    "#first create new data table of data_demog_prepost that contains the same number of rows for each participant in that is in psych_flex_CR\n",
    "#(e.g. replicate data_demog_prepost so same length as psych_flex_CR for each participant)\n",
    "\n",
    "participants = psych_flex_CR['MitreID'].unique()\n",
    "\n",
    "psych_flex_CR_demog = pd.DataFrame()\n",
    "\n",
    "for part in participants:\n",
    "    df_part_long = pd.concat([data_demog_prepost[data_demog_prepost['ID'] == part]]*len(psych_flex_CR[psych_flex_CR['MitreID'] ==  part]), ignore_index=True)\n",
    "    df_part_long.reset_index(inplace=True)\n",
    "    psych_flex_CR_demog_int = pd.concat([df_part_long, psych_flex_CR[psych_flex_CR['MitreID'] ==  part].reset_index()], axis = 1)\n",
    "    psych_flex_CR_demog = psych_flex_CR_demog.append(psych_flex_CR_demog_int)\n",
    "\n",
    "#confirm the two data tables are now the same lenght\n",
    "print('psych_flex_CR and psych_flex_CR_demog are the same length:', psych_flex_CR.shape[0] == psych_flex_CR_demog.shape[0])\n",
    "print(psych_flex_CR.shape[0])\n",
    "print(psych_flex_CR_demog.shape[0])\n",
    "print('does the math make sense?', psych_flex_CR_demog.shape[0] == (psych_flex_CR_demog['ID'].values == psych_flex_CR_demog['MitreID'].values).sum())\n",
    "psych_flex_CR_demog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psych_flex_CR_demog.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_CR_demog_features = ['MitreID', 'ParticipantID',\n",
    "       'PrimaryUnit', 'SmartPhone', 'Sex', 'Shift', 'Wave', 'bornUS', 'lang', 'englyrs', \n",
    "                        'activity_num', 'pf_mgt', 'exp_neg', 'exp_pos',\n",
    "       'exp_neut', 'ocb', 'inter.deviance', 'org.deviance', 'extraversion',\n",
    "       'agreeableness', 'conscientiousness', 'neuroticism', 'openness',\n",
    "       'psqi', 'fatigue', 'Stress', \n",
    "       'Flexibility', 'Inflexibility', 'Engagement', 'start_delay',\n",
    "       'time_to_complete', 'wave_study_day', 'survey_count', 'day_of_week',\n",
    "       'working', 'wave_study_date_bin', 'missing_values', 'uncompleted',\n",
    "       'uncompleted_day_bin', 'longest_string_count',\n",
    "       'longest_string_answer', 'longest_string_ratio',\n",
    "       'longest_string_ratio_bin', 'bad_times_low', 'bad_times_high',\n",
    "       'ls_7_ratio', 'ls_7_ratio_bin']\n",
    "\n",
    "PF_CR_features = ['activity_num', 'pf_mgt', 'exp_neg', 'exp_pos',\n",
    "       'exp_neut', 'day_of_week', 'working', 'start_delay',\n",
    "       'time_to_complete', 'wave_study_date_bin', 'missing_values', 'uncompleted',\n",
    "       'uncompleted_day_bin', 'longest_string_count',\n",
    "       'longest_string_answer', 'longest_string_ratio',\n",
    "       'longest_string_ratio_bin', 'bad_times_low', 'bad_times_high',\n",
    "       'ls_7_ratio', 'ls_7_ratio_bin']\n",
    "\n",
    "PF_CR_demog_df = psych_flex_CR_demog[PF_CR_demog_features]\n",
    "PF_CR_df = psych_flex_CR_demog[PF_CR_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_CR_demog_df.groupby('wave_study_date_bin').corr().to_csv('corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"longest_string_count\", data=PF_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"longest_string_answer\", data=PF_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"longest_string_ratio_bin\", data=PF_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"wave_study_date_bin\", y=\"ls_7_ratio_bin\", data=PF_CR_demog_df, kind=\"bar\")\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"longest_string_count\", y=\"bad_times_low\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', col_wrap=3)\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"longest_string_count\", y=\"ls_7_ratio\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', col_wrap=3)\n",
    "g.fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_CR_demog_df['MitreID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = PF_CR_demog_df['MitreID'].unique()\n",
    "for u_id in unique_ids:\n",
    "    g = sns.catplot(x=\"wave_study_day\", y=\"longest_string_count\", data=PF_CR_demog_df[PF_CR_demog_df['MitreID'] == u_id], kind=\"bar\")\n",
    "    g.fig.set_size_inches(10,5)\n",
    "    #axes = g.axes\n",
    "    plt.ylim([0,13])\n",
    "    #g.set_ylim(0, 13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get participant ID order when sorted by longest string in the last time bin\n",
    "wave_1_ls = PF_CR_demog_df[PF_CR_demog_df['wave_study_date_bin'] == PF_CR_demog_df['wave_study_date_bin'].unique()[-1]].sort_values('longest_string_count')\n",
    "ls_index = wave_1_ls['MitreID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"MitreID\", y=\"longest_string_count\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', \n",
    "                ci=None, order=ls_index)\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"MitreID\", y=\"ls_7_ratio_bin\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', \n",
    "                ci=None, order=ls_index)\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_bins = PF_CR_demog_df['wave_study_date_bin'].unique()\n",
    "plt.figure(figsize=(25, 10))\n",
    "ax = PF_CR_demog_df[PF_CR_demog_df['wave_study_date_bin'] == day_bins[0]].sort_values('longest_string_count').groupby(['ParticipantID'])['longest_string_count'].mean().plot(kind='bar')\n",
    "#ax = PF_CR_demog_df[PF_CR_demog_df['wave_study_date_bin'] == day_bins[1]].groupby(['ParticipantID'])['time_to_complete'].mean().plot(kind='bar')\n",
    "#ax = PF_CR_demog_df[PF_CR_demog_df['wave_study_date_bin'] == day_bins[2]].groupby(['ParticipantID'])['time_to_complete'].mean().plot(kind='bar')\n",
    "#ax = PF_CR_demog_df[PF_CR_demog_df['wave_study_date_bin'] == day_bins[3]].groupby(['ParticipantID'])['time_to_complete'].mean().plot(kind='bar')\n",
    "#ax = PF_CR_demog_df[PF_CR_demog_df['wave_study_date_bin'] == day_bins[4]].groupby(['ParticipantID'])['time_to_complete'].mean().plot(kind='bar')\n",
    "plt.legend(('job', 'health', 'personality', 'psych_flex', 'engage_psycap'))\n",
    "plt.title('Mean time to complete survey across time')\n",
    "ax.set_ylabel('Mean time to complete survey')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use order from above\n",
    "g = sns.catplot(x=\"MitreID\", y=\"longest_string_ratio_bin\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', \n",
    "                ci=None, order=ls_index)\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"bad_times\", y=\"longest_string_count\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin')\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"fatigue\", y=\"longest_string_count\", data=PF_CR_demog_df, kind=\"bar\", col='wave_study_date_bin', order=['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'])\n",
    "g.fig.set_size_inches(25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(PF_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"ocb\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(PF_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"org.deviance\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(PF_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"inter.deviance\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_CR_demog_df['Inflexibility'] = PF_CR_demog_df['Inflexibility'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(PF_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"Inflexibility\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_CR_demog_df['Stress'] = PF_CR_demog_df['Stress'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(PF_CR_demog_df, col=\"wave_study_date_bin\")\n",
    "g.map(sns.regplot, \"Stress\", \"longest_string_count\")\n",
    "g.fig.set_size_inches(25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CR summary feature (count of positive CR parameters)\n",
    "\n",
    "counts = []\n",
    "\n",
    "for index, row in psych_flex_only.iterrows():\n",
    "    count = 0\n",
    "    if row['missing_values'] > 0:\n",
    "        count += 1\n",
    "    #if row['uncompleted'] > 0:\n",
    "        #count += 1\n",
    "    if row['longest_string'] > 7:\n",
    "        count += 1\n",
    "    \n",
    "    counts.append(count)\n",
    "\n",
    "psych_flex_only['CR_count'] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "psych_flex_only.to_csv('psych_flex_only_CR.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
