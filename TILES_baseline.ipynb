{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Schindler/Documents/Schindler_Lab/ML projects/TILES/Data_googledrive/Demog, PRE, PST survey composites.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path)\n",
    "data = pd.DataFrame(data = data)\n",
    "print('Composites shape:\\n', data.shape, '\\n')\n",
    "print('Composites data types:\\n', data.info(), '\\n')\n",
    "data_pre = data[['ID', 'shipley.vocab', 'shipley.abs', 'irb', 'itp',\n",
    "       'ocb', 'inter.deviance', 'org.deviance', 'extraversion',\n",
    "       'agreeableness', 'conscientiousness', 'neuroticism', 'openness',\n",
    "       'pos.affect', 'neg.affect', 'stai.trait', 'audit', 'gats.status',\n",
    "       'gats.quantity', 'ipaq', 'psqi', 'gender', 'age',\n",
    "       'bornUS', 'country', 'lang', 'englyrs', 'educ', 'jobstat', 'occup',\n",
    "       'occup_TEXT', 'supervise', 'quantsup', 'size', 'duration',\n",
    "       'income', 'record_id', 'race', 'ethnic', 'relationship',\n",
    "       'pregnant', 'children', 'housing', 'household___1',\n",
    "       'household___2', 'household___3', 'household___4', 'household___5',\n",
    "       'household___6', 'household___7', 'currentposition',\n",
    "       'position_other', 'certifications', 'nurseyears', 'shift', 'hours',\n",
    "       'overtime', 'commute_type', 'commute_time', 'extrajob',\n",
    "       'extrahours', 'student', 'mpfi24_01', 'mpfi24_02', 'mpfi24_03', 'mpfi24_04', 'mpfi24_05',\n",
    "       'mpfi24_06', 'mpfi24_07', 'mpfi24_08', 'mpfi24_09', 'mpfi24_10',\n",
    "       'mpfi24_11', 'mpfi24_12', 'mpfi24_13', 'mpfi24_14', 'mpfi24_15',\n",
    "       'mpfi24_16', 'mpfi24_17', 'mpfi24_18', 'mpfi24_19', 'mpfi24_20',\n",
    "       'mpfi24_21', 'mpfi24_22', 'mpfi24_23', 'mpfi24_24',\n",
    "       'General_Health', 'Physical_Functioning', 'Limits_Physical',\n",
    "       'Emotional_Wellbeing', 'Limits_Emotional', 'Social_Functioning',\n",
    "       'Pain', 'energy', 'fatigue', 'LifeSatisfaction', 'Stress', 'WAAQ',\n",
    "       'Flexibility', 'Inflexibility', 'Acceptance', 'Awareness',\n",
    "       'Self_as_Context', 'Defusion', 'Values', 'Action', 'Avoidance',\n",
    "       'LackofAwareness', 'Self_as_Content', 'Fusion', 'LackofValues',\n",
    "       'Inaction', 'Engagement', 'Engage_Vigor', 'Engage_Dedication',\n",
    "       'Engage_Absorbtion', 'PsyCap', 'Psycap_Hope', 'Psycap_Efficacy',\n",
    "       'Psycap_Reslilience', 'Psycap_Optimism', 'challengestressors',\n",
    "       'Hindrancestressors']]\n",
    "data_pre = data_pre.set_index('ID')\n",
    "print(data_pre.shape)\n",
    "data_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill empty values with NaN\n",
    "data_pre = data_pre.replace(' ', np.nan)\n",
    "#look at columns with missing values\n",
    "print('Composites missing value counts:\\n', data_pre.isna().sum().sort_values(ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_pre.shape)\n",
    "data_clean = data_pre.dropna(axis=1, thresh=210)\n",
    "print(data_clean.shape)\n",
    "data_clean = data_clean.dropna(axis=0)\n",
    "print(data_clean.shape)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_clean.info())\n",
    "data_clean['gats.status'] = data_clean['gats.status'].replace({'never': 0, 'past': 1, 'current': 2})\n",
    "data_clean = data_clean.astype('float')\n",
    "print(data_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data_clean.columns.values\n",
    "sns.pairplot(data_clean, x_vars=columns, y_vars='supervise', kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_clean.corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    sns.distplot(data_clean[col], bins=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demo = data_pre[['race', 'ethnic', 'relationship', 'pregnant',\n",
    "       'children', 'housing', 'currentposition',\n",
    "       'position_other', 'certifications', 'nurseyears', 'shift', 'hours',\n",
    "       'overtime', 'commute_type', 'commute_time', 'extrajob',\n",
    "       'extrahours', 'student']]\n",
    "print(data_demo.shape)\n",
    "print(data_demo.isna().sum())\n",
    "data_demo_clean = data_demo.dropna(axis = 1, thresh=175)\n",
    "print(data_demo_clean.shape)\n",
    "data_demo_clean = data_demo_clean.dropna(axis = 0, thresh=16)\n",
    "print(data_demo_clean.shape)\n",
    "print(data_demo_clean.info())\n",
    "data_demo_clean = data_demo_clean.astype('float')\n",
    "print(data_demo_clean.info())\n",
    "print(data_demo_clean.isnull().values.any())\n",
    "data_demo_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_scaled = scaler.fit_transform(data_demo_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2,50)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=39)\n",
    "    km_ss.fit(data_scaled)\n",
    "    scores.append(silhouette_score(data_scaled, km_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km2 = KMeans(n_clusters=2,random_state=1234)\n",
    "km2.fit(features_clust_scaled)\n",
    "data['kmeans_2_scaled'] = [ \"cluster_\" + str(label) for label in km2.labels_ ]\n",
    "data.groupby('kmeans_2_scaled').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Severity')['kmeans_2_scaled'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
